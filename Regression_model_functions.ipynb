{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e485011f-be1e-4e77-902c-f482ac14776e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3 is /home/ec2-user/anaconda3/envs/python3/bin/python3\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting xgboost\n",
      "  Downloading xgboost-1.7.5-py3-none-manylinux2014_x86_64.whl (200.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.3/200.3 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from xgboost) (1.10.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from xgboost) (1.22.3)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.7.5\n"
     ]
    }
   ],
   "source": [
    "!type python3\n",
    "!/home/ec2-user/anaconda3/envs/python3/bin/python3 -m pip install  xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f53beb4-7e0d-4c57-b12b-495001c62de7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports finished...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "import xgboost as xgb\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "from sklearn import ensemble\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.linear_model import TheilSenRegressor\n",
    "print('Imports finished...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7119bf7c-ef10-4b41-b226-3ea163c26a02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Basic functions for evaluations\n",
    "\n",
    "def get_y_pred(model, x_test):\n",
    "    \"\"\"\n",
    "    This function is to predict x_test on a model already trained.\n",
    "    \"\"\"\n",
    "    return model.predict(x_test)\n",
    "\n",
    "def get_rmse_test_data(y_test, y_pred):\n",
    "    \"\"\"\n",
    "    This function is to get RMSE between y_test and y_pred\n",
    "    \"\"\"\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    return rmse\n",
    "\n",
    "def get_r2_score(y_test, y_pred):\n",
    "    \"\"\"\n",
    "    This function is to get R2 between prediction and actual.\n",
    "    \"\"\"\n",
    "    r2score = r2_score(y_test, y_pred)\n",
    "    return r2score\n",
    "\n",
    "def get_mae(y_test, y_pred):\n",
    "    \"\"\"\n",
    "    This function is to get R2 between prediction and actual.\n",
    "    \"\"\"\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    return mae\n",
    "\n",
    "def generate_result_df(model_name, parameters, rmse, r2score, mae, importance_list):\n",
    "    \"\"\"\n",
    "    This function generates a DF with results\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        \"Model\": model_name, \n",
    "        \"Parameters\": parameters,\n",
    "        \"RMSE\": str(round(rmse,2)),\n",
    "        \"R2 Score\": str(round(r2score,2)),\n",
    "        \"MAE\": str(round(mae,2)),\n",
    "        \"Feature Importance\": importance_list\n",
    "    }\n",
    "    df = pd.DataFrame([results])\n",
    "    display(df)\n",
    "    return df\n",
    "\n",
    "def get_feature_importance(model, model_name, x_column_names):\n",
    "    if model_name == 'DecissionTree Regressor' or model_name == 'RandomForest Regressor' or model_name == 'XGBoost' or model_name == 'Gradient Boost':\n",
    "        importance = model.feature_importances_\n",
    "    else:\n",
    "        importance = model.coef_\n",
    "    importance_list = []\n",
    "    for i,v in enumerate(importance):\n",
    "        importance_list.append((x_column_names[i], v))\n",
    "    return importance_list\n",
    "    \n",
    "def graph_pred_real_data_comparison(y_test, y_pred, model_name):\n",
    "    \"\"\"\n",
    "    This function generates a chart comparing y_train and y_test\n",
    "    \"\"\"\n",
    "    x_ax = range(len(y_test))\n",
    "    plt.plot(x_ax, y_test, label=\"original\")\n",
    "    plt.plot(x_ax, y_pred, label=\"predicted\")\n",
    "    plt.title(model_name)\n",
    "    plt.xlabel('X-axis')\n",
    "    plt.ylabel('Y-axis')\n",
    "    plt.legend(loc='best',fancybox=True, shadow=True)\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a06f9cc-2d53-4fc9-9b48-39a788defe39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def linear_regression(x_train, y_train, x_test, y_test, x_column_names):\n",
    "    '''\n",
    "    Model for linear regression. Returns DF with results\n",
    "    '''\n",
    "    model_name = \"Lineal Regression\"\n",
    "    lin_reg = LinearRegression()\n",
    "    lin_reg.fit(x_train,y_train)\n",
    "    y_pred = get_y_pred(lin_reg, x_test)\n",
    "    rmse = get_rmse_test_data(y_test,y_pred)\n",
    "    r2score = get_r2_score(y_test,y_pred)\n",
    "    mae = get_mae(y_test,y_pred)\n",
    "    # graph_pred_real_data_comparison(y_test, y_pred, model_name)\n",
    "    importance_list = get_feature_importance(lin_reg, model_name, x_column_names)\n",
    "    df = generate_result_df(model_name, 'NA', rmse, r2score, mae, importance_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cec00dd-d9db-455a-baf8-bf92e0604143",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ransac(x_train, y_train, x_test, y_test, x_column_names):\n",
    "    '''\n",
    "    Model for RANSAC regression. Returns DF with results\n",
    "    '''\n",
    "    model_name = \"RANSAC\"\n",
    "    ransac_model = RANSACRegressor()\n",
    "    ransac_model.fit(x_train, y_train)\n",
    "    y_pred = get_y_pred(ransac_model, x_test)\n",
    "    rmse = get_rmse_test_data(y_test,y_pred)\n",
    "    r2score = get_r2_score(y_test,y_pred)\n",
    "    mae = get_mae(y_test,y_pred)\n",
    "    importance_list = get_feature_importance(ransac_model, model_name, x_column_names)\n",
    "    # graph_pred_real_data_comparison(y_test, y_pred, model_name)\n",
    "    df = generate_result_df(model_name, 'NA', rmse, r2score, mae, importance_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7459e254-018a-46b6-b742-965626ac8a95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ridge(x_train, y_train, x_test, y_test, x_column_names):\n",
    "    '''\n",
    "    Model for Ridge regression. Returns DF with results\n",
    "    '''\n",
    "    model_name = \"Ridge\"\n",
    "    ridge_model = Ridge()\n",
    "    ridge_model.fit(x_train, y_train)\n",
    "    y_pred = get_y_pred(ridge_model, x_test)\n",
    "    rmse = get_rmse_test_data(y_test,y_pred)\n",
    "    r2score = get_r2_score(y_test,y_pred)\n",
    "    mae = get_mae(y_test,y_pred)\n",
    "    importance_list = get_feature_importance(ridge_model, model_name, x_column_names)\n",
    "    # graph_pred_real_data_comparison(y_test, y_pred, model_name)\n",
    "    df = generate_result_df(model_name, 'NA', rmse, r2score, mae, importance_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9ff0a52-3237-48b3-bcf6-aecf4b0c420c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def elasticnet(x_train, y_train, x_test, y_test, x_column_names):\n",
    "    '''\n",
    "    Model for ElasticNet regression. Returns DF with results\n",
    "    '''\n",
    "    model_name = \"ElasticNet\"\n",
    "    elasticnet_model = ElasticNet()\n",
    "    elasticnet_model.fit(x_train, y_train)\n",
    "    y_pred = get_y_pred(elasticnet_model, x_test)\n",
    "    rmse = get_rmse_test_data(y_test,y_pred)\n",
    "    r2score = get_r2_score(y_test,y_pred)\n",
    "    mae = get_mae(y_test,y_pred)\n",
    "    importance_list = get_feature_importance(elasticnet_model, model_name, x_column_names)\n",
    "    # graph_pred_real_data_comparison(y_test, y_pred, model_name)\n",
    "    df = generate_result_df(model_name, 'NA', rmse, r2score, mae, importance_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9e3af92-0dbc-4144-8d6a-bbfc45b465e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def linearsvr(x_train, y_train, x_test, y_test, x_column_names):\n",
    "    '''\n",
    "    Model for LinearSVR regression. Returns DF with results\n",
    "    '''\n",
    "    model_name = \"Linear SVR\"\n",
    "    param_grid_gb = {\n",
    "                        # 'C': [1, 10, 100, 1000],\n",
    "                        'C': [1, 10],\n",
    "                        # 'max_iter': [1000, 2000],\n",
    "                        'max_iter': [10000, 20000],\n",
    "                        'loss': ['epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "                        'epsilon': [0, 0.01, 0.1, 0.3]\n",
    "                    }\n",
    "    linearSVR_model = LinearSVR()\n",
    "    mse_grid = GridSearchCV(estimator = linearSVR_model, param_grid = param_grid_gb, scoring = 'neg_mean_squared_error', cv = 2, verbose = 2)\n",
    "    mse_grid.fit(x_train, y_train)\n",
    "    best_parameters = mse_grid.best_params_\n",
    "    best_linearSVR_model = LinearSVR(C=best_parameters['C'], max_iter=best_parameters['max_iter'], loss=best_parameters['loss'], epsilon=best_parameters['epsilon'])\n",
    "    best_linearSVR_model.fit(x_train, y_train)\n",
    "    y_pred = get_y_pred(best_linearSVR_model, x_test)\n",
    "    rmse = get_rmse_test_data(y_test,y_pred)\n",
    "    r2score = get_r2_score(y_test,y_pred)\n",
    "    mae = get_mae(y_test,y_pred)\n",
    "    importance_list = get_feature_importance(best_linearSVR_model, model_name, x_column_names)\n",
    "    # graph_pred_real_data_comparison(y_test, y_pred, model_name)\n",
    "    df = generate_result_df(model_name, best_parameters, rmse, r2score, mae, importance_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89445f23-23da-4dbe-bd62-50e2f1c89288",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bayesianridge(x_train, y_train, x_test, y_test, x_column_names):\n",
    "    '''\n",
    "    Model for Bayesian Ridge regression. Returns DF with results\n",
    "    '''\n",
    "    model_name = \"Bayesian Ridge\"\n",
    "    BayesianRidge_model = BayesianRidge()\n",
    "    BayesianRidge_model.fit(x_train, y_train)\n",
    "    y_pred = get_y_pred(BayesianRidge_model, x_test)\n",
    "    rmse = get_rmse_test_data(y_test,y_pred)\n",
    "    r2score = get_r2_score(y_test,y_pred)\n",
    "    mae = get_mae(y_test,y_pred)\n",
    "    importance_list = get_feature_importance(BayesianRidge_model, model_name, x_column_names)\n",
    "    # graph_pred_real_data_comparison(y_test, y_pred, model_name)\n",
    "    df = generate_result_df(model_name, 'NA', rmse, r2score, mae, importance_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa08e0b9-99a8-42b4-9933-ffa8ba5cdd21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lasso(x_train, y_train, x_test, y_test, x_column_names):\n",
    "    '''\n",
    "    Model for Lasso regression. Returns DF with results\n",
    "    '''\n",
    "    model_name = \"Lasso\"\n",
    "    Lasso_model = Lasso()\n",
    "    Lasso_model.fit(x_train, y_train)\n",
    "    y_pred = get_y_pred(Lasso_model, x_test)\n",
    "    rmse = get_rmse_test_data(y_test,y_pred)\n",
    "    r2score = get_r2_score(y_test,y_pred)\n",
    "    mae = get_mae(y_test,y_pred)\n",
    "    importance_list = get_feature_importance(Lasso_model, model_name, x_column_names)\n",
    "    # graph_pred_real_data_comparison(y_test, y_pred, model_name)\n",
    "    df = generate_result_df(model_name, 'NA', rmse, r2score, mae, importance_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69d309f5-8a50-4ce0-a2cc-f8074fd2b82f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decisiontree_regressor(x_train, y_train, x_test, y_test, x_column_names):\n",
    "    '''\n",
    "    Model for DecisionTree regressor. Returns DF with results\n",
    "    '''\n",
    "    model_name = \"DecissionTree Regressor\"\n",
    "    param_grid_gb = {'splitter': ['best', 'random'],\n",
    "                     # 'max_features': ['auto', 'sqrt', 'log2'],\n",
    "                     'max_features': [1, 'sqrt'],\n",
    "                      'min_samples_split': [2, 5, 10],\n",
    "                     'min_samples_leaf': [5]\n",
    "                    }\n",
    "    DecisionTreeRegressor_model = DecisionTreeRegressor()\n",
    "    mse_grid = GridSearchCV(estimator = DecisionTreeRegressor_model, param_grid = param_grid_gb, scoring = 'neg_mean_squared_error', cv = 2, verbose = 2)\n",
    "    mse_grid.fit(x_train, y_train)\n",
    "    best_parameters = mse_grid.best_params_\n",
    "    best_decissiontree_regressor_model = DecisionTreeRegressor(splitter=best_parameters['splitter'], max_features=best_parameters['max_features'], min_samples_split=best_parameters['min_samples_split'], min_samples_leaf=best_parameters['min_samples_leaf'])\n",
    "    best_decissiontree_regressor_model.fit(x_train, y_train)\n",
    "    y_pred = get_y_pred(best_decissiontree_regressor_model, x_test)\n",
    "    rmse = get_rmse_test_data(y_test,y_pred)\n",
    "    r2score = get_r2_score(y_test,y_pred)\n",
    "    mae = get_mae(y_test,y_pred)\n",
    "    importance_list = get_feature_importance(best_decissiontree_regressor_model, model_name, x_column_names)\n",
    "    # graph_pred_real_data_comparison(y_test, y_pred, model_name)\n",
    "    df = generate_result_df(model_name, best_parameters, rmse, r2score, mae, importance_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37f71c3d-7033-4c81-8086-d3df9f9879c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def randomforest_regressor(x_train, y_train, x_test, y_test, x_column_names):\n",
    "    '''\n",
    "    Model for RadomForest regressor. Returns DF with results\n",
    "    '''\n",
    "    model_name = \"RandomForest Regressor\"\n",
    "    param_grid_gb = {'n_estimators': [600, 900, 1200],\n",
    "                     # 'max_features': [0.3, 0.6, 1],\n",
    "                     # 'max_features': [0.3, 0.6],\n",
    "                     'max_features': [0.6, 0.8],\n",
    "                     # 'min_samples_split': [1, 3, 5, 10, 15, 100],\n",
    "                     'min_samples_split': [5, 10],\n",
    "                     # 'min_samples_leaf': [1, 2, 5, 10]\n",
    "                     'min_samples_leaf': [1]\n",
    "                     # 'min_samples_leaf': [1, 2]\n",
    "                    }\n",
    "    rfg_model = RandomForestRegressor()\n",
    "    mse_grid = GridSearchCV(estimator = rfg_model, param_grid = param_grid_gb, scoring = 'neg_mean_squared_error', cv = 1, verbose = 2)\n",
    "    mse_grid.fit(x_train, y_train)\n",
    "    best_parameters = mse_grid.best_params_\n",
    "    best_rf_regresor_model = RandomForestRegressor(n_estimators=best_parameters['n_estimators'], max_features=best_parameters['max_features'])\n",
    "    best_rf_regresor_model.fit(x_train, y_train)\n",
    "    y_pred = get_y_pred(best_rf_regresor_model, x_test)\n",
    "    rmse = get_rmse_test_data(y_test,y_pred)\n",
    "    r2score = get_r2_score(y_test,y_pred)\n",
    "    mae = get_mae(y_test,y_pred)\n",
    "    importance_list = get_feature_importance(best_rf_regresor_model, model_name, x_column_names)\n",
    "    # graph_pred_real_data_comparison(y_test, y_pred, model_name)\n",
    "    df = generate_result_df(model_name, best_parameters, rmse, r2score, mae, importance_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64089006-e338-41e4-9666-fc8d906c29e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def xgboost(x_train, y_train, x_test, y_test, x_column_names):\n",
    "    '''\n",
    "    Model for Xgboost regressor. Returns DF with results\n",
    "    '''\n",
    "    model_name = \"XGBoost\"\n",
    "    param_grid_gb = {\n",
    "                     # 'learning_rate': [0.3, 0.01, 0.1, 0.6, 0.9],\n",
    "                     'learning_rate': [0.01],\n",
    "                     # 'n_estimators' : [200, 300, 600],\n",
    "                     'n_estimators' : [600],\n",
    "                     # 'subsample' : [1, 0.1, 0.6],\n",
    "                     'subsample' : [0.6],\n",
    "                     'min_split_loss': [0, 10, 50],\n",
    "                     # 'max_depth': [6, 10, 100]\n",
    "                     'max_depth': [10, 100]\n",
    "                    }\n",
    "    xgb_model = xgb.XGBRegressor()\n",
    "    mse_grid = GridSearchCV(estimator = xgb_model, param_grid = param_grid_gb, scoring = 'neg_mean_squared_error', cv = 2, verbose = 2)\n",
    "    mse_grid.fit(x_train, y_train)\n",
    "    best_parameters = mse_grid.best_params_\n",
    "    best_xgboost_model = xgb.XGBRegressor(learning_rate=best_parameters['learning_rate'], n_estimators=best_parameters['n_estimators'], subsample=best_parameters['subsample'], min_split_loss=best_parameters['min_split_loss'], max_depth=best_parameters['max_depth'])\n",
    "    best_xgboost_model.fit(x_train, y_train)\n",
    "    y_pred = get_y_pred(best_xgboost_model, x_test)\n",
    "    rmse = get_rmse_test_data(y_test,y_pred)\n",
    "    mae = get_mae(y_test,y_pred)\n",
    "    r2score = get_r2_score(y_test,y_pred)\n",
    "    importance_list = get_feature_importance(best_xgboost_model, model_name, x_column_names)\n",
    "    # graph_pred_real_data_comparison(y_test, y_pred, model_name)\n",
    "    df = generate_result_df(model_name, best_parameters, rmse, r2score, mae, importance_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71a10d24-d740-4087-ac21-de493e8bcf0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gradientboost_regressor(x_train, y_train, x_test, y_test, x_column_names):\n",
    "    '''\n",
    "    Model for gradient boost regressor from scklearn. Returns DF with results\n",
    "    '''\n",
    "    model_name = \"Gradient Boost\"\n",
    "    param_grid_gb = {\n",
    "                     # 'learning_rate': [0.3, 0.1, 0.6, 0.9],\n",
    "                     'learning_rate': [0.1],\n",
    "                     # 'n_estimators' : [200, 400, 600, 800],\n",
    "                     'n_estimators' : [400, 600, 800],\n",
    "                     'min_samples_split': [5, 15],\n",
    "                    'loss': 'huber'\n",
    "                    }\n",
    "    gradientBoost_model = ensemble.GradientBoostingRegressor()\n",
    "    mse_grid = GridSearchCV(estimator = gradientBoost_model, param_grid = param_grid_gb, scoring = 'neg_mean_squared_error', cv = 2, verbose = 2)\n",
    "    mse_grid.fit(x_train, y_train)\n",
    "    best_parameters = mse_grid.best_params_\n",
    "    best_gradientboost_model = ensemble.GradientBoostingRegressor(learning_rate=best_parameters['learning_rate'], n_estimators=best_parameters['n_estimators'], min_samples_split=best_parameters['min_samples_split'])\n",
    "    best_gradientboost_model.fit(x_train, y_train)\n",
    "    y_pred = get_y_pred(best_gradientboost_model, x_test)\n",
    "    rmse = get_rmse_test_data(y_test,y_pred)\n",
    "    r2score = get_r2_score(y_test,y_pred)\n",
    "    mae = get_mae(y_test,y_pred)\n",
    "    importance_list = get_feature_importance(best_gradientboost_model, model_name, x_column_names)\n",
    "    # graph_pred_real_data_comparison(y_test, y_pred, model_name)\n",
    "    df = generate_result_df(model_name, best_parameters, rmse, r2score, mae, importance_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0e46cb4-ca50-4995-8633-31814045fb21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sgd_regressor(x_train, y_train, x_test, y_test, x_column_names):\n",
    "    '''\n",
    "    Model for sgd regressor from scklearn. Returns DF with results\n",
    "    '''\n",
    "    model_name = \"SGD\"\n",
    "    param_grid_gb = {\n",
    "                     'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "                     # 'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
    "                     'alpha': [0.001, 0.1],\n",
    "                     'epsilon': [0.1, 0.05],\n",
    "                     'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "                     'eta0' : [0.01, 0.1],\n",
    "                     'power_t': [0.25, 0.1]\n",
    "                    }\n",
    "    sgdr_model = SGDRegressor()\n",
    "    mse_grid = GridSearchCV(estimator = sgdr_model, param_grid = param_grid_gb, scoring = 'neg_mean_squared_error', cv = 2, verbose = 2)\n",
    "    mse_grid.fit(x_train, y_train)\n",
    "    best_parameters = mse_grid.best_params_\n",
    "    best_sgd_model = SGDRegressor(learning_rate=best_parameters['learning_rate'], penalty=best_parameters['penalty'], alpha=best_parameters['alpha'], epsilon=best_parameters['epsilon'], eta0=best_parameters['eta0'], power_t=best_parameters['power_t'])\n",
    "    best_sgd_model.fit(x_train, y_train)\n",
    "    y_pred = get_y_pred(best_sgd_model, x_test)\n",
    "    rmse = get_rmse_test_data(y_test,y_pred)\n",
    "    r2score = get_r2_score(y_test,y_pred)\n",
    "    mae = get_mae(y_test,y_pred)\n",
    "    importance_list = get_feature_importance(best_sgd_model, model_name, x_column_names)\n",
    "    # graph_pred_real_data_comparison(y_test, y_pred, model_name)\n",
    "    df = generate_result_df(model_name, best_parameters, rmse, r2score, mae, importance_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "119987a6-c477-4c2d-beb6-d0d50d80566f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def huber_regressor(x_train, y_train, x_test, y_test, x_column_names):\n",
    "    '''\n",
    "    Model for Huber regressor from scklearn. Returns DF with results\n",
    "    '''\n",
    "    model_name = \"Huber\"\n",
    "    param_grid_gb = {\n",
    "                     'alpha': [0.001, 0.01],\n",
    "                     # 'epsilon': [1, 1.35, 1.8, 3],\n",
    "                     'epsilon': [1.8, 3],\n",
    "                     'max_iter': [100, 300]\n",
    "                    }\n",
    "    huber_model = HuberRegressor()\n",
    "    mse_grid = GridSearchCV(estimator = huber_model, param_grid = param_grid_gb, scoring = 'neg_mean_squared_error', cv = 2, verbose = 2)\n",
    "    mse_grid.fit(x_train, y_train)\n",
    "    best_parameters = mse_grid.best_params_\n",
    "    best_huber_model = HuberRegressor(alpha=best_parameters['alpha'], epsilon=best_parameters['epsilon'], max_iter=best_parameters['max_iter'])\n",
    "    best_huber_model.fit(x_train, y_train)\n",
    "    y_pred = get_y_pred(best_huber_model, x_test)\n",
    "    rmse = get_rmse_test_data(y_test,y_pred)\n",
    "    r2score = get_r2_score(y_test,y_pred)\n",
    "    mae = get_mae(y_test,y_pred)\n",
    "    importance_list = get_feature_importance(best_huber_model, model_name, x_column_names)\n",
    "    # graph_pred_real_data_comparison(y_test, y_pred, model_name)\n",
    "    df = generate_result_df(model_name, best_parameters, rmse, r2score, mae, importance_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad3588e-1492-401d-a144-c287dcf12cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def theilsen_regressor(x_train, y_train, x_test, y_test, x_column_names):\n",
    "    '''\n",
    "    Model for TheilSen regressor from scklearn. Returns DF with results\n",
    "    '''\n",
    "    model_name = \"TheilSen\"\n",
    "    param_grid_gb = {\n",
    "                     'max_iter': [400, 800]\n",
    "                    }\n",
    "    theilsen_model = TheilSenRegressor()\n",
    "    mse_grid = GridSearchCV(estimator = theilsen_model, param_grid = param_grid_gb, scoring = 'neg_mean_squared_error', cv = 2, verbose = 2)\n",
    "    mse_grid.fit(x_train, y_train)\n",
    "    best_parameters = mse_grid.best_params_\n",
    "    best_theilsen_model = TheilSenRegressor(max_iter=best_parameters['max_iter'])\n",
    "    best_theilsen_model.fit(x_train, y_train)\n",
    "    y_pred = get_y_pred(best_theilsen_model, x_test)\n",
    "    rmse = get_rmse_test_data(y_test,y_pred)\n",
    "    r2score = get_r2_score(y_test,y_pred)\n",
    "    mae = get_mae(y_test,y_pred)\n",
    "    importance_list = get_feature_importance(best_theilsen_model, model_name, x_column_names)\n",
    "    # graph_pred_real_data_comparison(y_test, y_pred, model_name)\n",
    "    df = generate_result_df(model_name, best_parameters, rmse, r2score, mae, importance_list)\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
